{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7q5aJu0IdRC",
        "outputId": "cc98a60a-5bbc-4fbc-f3ce-d86479c62691"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XSTFxNhSlz-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66ba7cf-a5e3-4c04-d1e4-2b807e5dd8cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Silver Layer Processing...\n",
            "Bronze data loaded. Starting transformations...\n",
            "\n",
            "Data Quality Metrics:\n",
            "Total Records: 25514\n",
            "Valid Records: 8406\n",
            "Invalid Records: 17108\n",
            "\n",
            "Null Percentages:\n",
            "time: 67.05%\n",
            "finish_time: 68.62%\n",
            "race_timestamp: 67.05%\n",
            "\n",
            "Writing to silver layer...\n",
            "\n",
            "Silver layer data written to: /content/drive/MyDrive/Capstone/silver\n",
            "Silver Layer Processing Complete!\n",
            "\n",
            "Sample of processed data:\n",
            "+------+-----+------------------+----------+---------+--------------------+----------+--------------------+-----------+------------+----------------+---------------+--------------+----------------+--------------+-----------------+------------------+--------+------+----+----+--------+-----------+-------------------+----------------+-----------------+---------------+-------------+-------------+---------------+--------------------+\n",
            "|season|round|          raceName|      date|     time|                 url|circuit_id|        circuit_name|circuit_lat|circuit_long|circuit_locality|circuit_country|constructor_id|constructor_name|     driver_id|driver_given_name|driver_family_name|position|points|grid|laps|  status|finish_time|     race_timestamp|driver_full_name|is_valid_position|is_valid_points|is_valid_grid|is_valid_date|is_valid_record| processed_timestamp|\n",
            "+------+-----+------------------+----------+---------+--------------------+----------+--------------------+-----------+------------+----------------+---------------+--------------+----------------+--------------+-----------------+------------------+--------+------+----+----+--------+-----------+-------------------+----------------+-----------------+---------------+-------------+-------------+---------------+--------------------+\n",
            "|  2024|    1|Bahrain Grand Prix|2024-03-02|15:00:00Z|https://en.wikipe...|   bahrain|Bahrain Internati...|    26.0325|     50.5106|          Sakhir|        Bahrain|      red_bull|        Red Bull|max_verstappen|              Max|        Verstappen|       1|    26|   1|  57|Finished|1:31:44.742|2024-03-02 15:00:00|  Max Verstappen|             true|           true|         true|         true|           true|2025-05-13 05:35:...|\n",
            "|  2024|    1|Bahrain Grand Prix|2024-03-02|15:00:00Z|https://en.wikipe...|   bahrain|Bahrain Internati...|    26.0325|     50.5106|          Sakhir|        Bahrain|      red_bull|        Red Bull|         perez|           Sergio|             Pérez|       2|    18|   5|  57|Finished|    +22.457|2024-03-02 15:00:00|    Sergio Pérez|             true|           true|         true|         true|           true|2025-05-13 05:35:...|\n",
            "|  2024|    1|Bahrain Grand Prix|2024-03-02|15:00:00Z|https://en.wikipe...|   bahrain|Bahrain Internati...|    26.0325|     50.5106|          Sakhir|        Bahrain|       ferrari|         Ferrari|         sainz|           Carlos|             Sainz|       3|    15|   4|  57|Finished|    +25.110|2024-03-02 15:00:00|    Carlos Sainz|             true|           true|         true|         true|           true|2025-05-13 05:35:...|\n",
            "|  2024|    1|Bahrain Grand Prix|2024-03-02|15:00:00Z|https://en.wikipe...|   bahrain|Bahrain Internati...|    26.0325|     50.5106|          Sakhir|        Bahrain|       ferrari|         Ferrari|       leclerc|          Charles|           Leclerc|       4|    12|   2|  57|Finished|    +39.669|2024-03-02 15:00:00| Charles Leclerc|             true|           true|         true|         true|           true|2025-05-13 05:35:...|\n",
            "|  2024|    1|Bahrain Grand Prix|2024-03-02|15:00:00Z|https://en.wikipe...|   bahrain|Bahrain Internati...|    26.0325|     50.5106|          Sakhir|        Bahrain|      mercedes|        Mercedes|       russell|           George|           Russell|       5|    10|   3|  57|Finished|    +46.788|2024-03-02 15:00:00|  George Russell|             true|           true|         true|         true|           true|2025-05-13 05:35:...|\n",
            "+------+-----+------------------+----------+---------+--------------------+----------+--------------------+-----------+------------+----------------+---------------+--------------+----------------+--------------+-----------------+------------------+--------+------+----+----+--------+-----------+-------------------+----------------+-----------------+---------------+-------------+-------------+---------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession, Window\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import types as T\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# Initialize Spark Session (without Delta configurations)\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"F1SilverLayer\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# First, let's read the parquet files and see what we're working with\n",
        "def process_f1_silver_layer():\n",
        "    try:\n",
        "        print(\"Starting Silver Layer Processing...\")\n",
        "\n",
        "        # Read the parquet files\n",
        "        bronze_df = spark.read.json(\n",
        "            \"/content/drive/MyDrive/Capstone/bronze/season=*\"\n",
        "        )\n",
        "\n",
        "        print(\"Bronze data loaded. Starting transformations...\")\n",
        "\n",
        "        # 1. Explode nested structures\n",
        "        df = bronze_df.select(\n",
        "            F.col(\"season\"),\n",
        "            F.col(\"round\"),\n",
        "            F.col(\"raceName\"),\n",
        "            F.col(\"date\"),\n",
        "            F.col(\"time\"),\n",
        "            F.col(\"url\"),\n",
        "            F.col(\"Circuit\").alias(\"circuit\"),\n",
        "            F.explode(\"Results\").alias(\"result\")\n",
        "        )\n",
        "\n",
        "        # 2. Flatten nested structures\n",
        "        df = df.select(\n",
        "            \"*\",\n",
        "            F.col(\"circuit.circuitId\").alias(\"circuit_id\"),\n",
        "            F.col(\"circuit.circuitName\").alias(\"circuit_name\"),\n",
        "            F.col(\"circuit.Location.lat\").alias(\"circuit_lat\"),\n",
        "            F.col(\"circuit.Location.long\").alias(\"circuit_long\"),\n",
        "            F.col(\"circuit.Location.locality\").alias(\"circuit_locality\"),\n",
        "            F.col(\"circuit.Location.country\").alias(\"circuit_country\"),\n",
        "            F.col(\"result.Constructor.constructorId\").alias(\"constructor_id\"),\n",
        "            F.col(\"result.Constructor.name\").alias(\"constructor_name\"),\n",
        "            F.col(\"result.Driver.driverId\").alias(\"driver_id\"),\n",
        "            F.col(\"result.Driver.givenName\").alias(\"driver_given_name\"),\n",
        "            F.col(\"result.Driver.familyName\").alias(\"driver_family_name\"),\n",
        "            F.col(\"result.position\").alias(\"position\"),\n",
        "            F.col(\"result.points\").alias(\"points\"),\n",
        "            F.col(\"result.grid\").alias(\"grid\"),\n",
        "            F.col(\"result.laps\").alias(\"laps\"),\n",
        "            F.col(\"result.status\").alias(\"status\"),\n",
        "            F.col(\"result.Time.time\").alias(\"finish_time\")\n",
        "        ).drop(\"circuit\", \"result\")\n",
        "\n",
        "        # 3. Data type conversions and standardization\n",
        "        df = df.withColumn(\"race_timestamp\",\n",
        "                          F.to_timestamp(\n",
        "                              F.concat(F.col(\"date\"), F.lit(\" \"), F.col(\"time\")),\n",
        "                              \"yyyy-MM-dd HH:mm:ssX\"\n",
        "                          ))\n",
        "\n",
        "        # 4. Add computed columns\n",
        "        df = df.withColumn(\"driver_full_name\",\n",
        "                          F.concat(F.col(\"driver_given_name\"),\n",
        "                                 F.lit(\" \"),\n",
        "                                 F.col(\"driver_family_name\")))\n",
        "\n",
        "        # 5. Data quality checks\n",
        "        df = df.withColumn(\"is_valid_position\",\n",
        "                          (F.col(\"position\").isNotNull() &\n",
        "                           F.col(\"position\").cast(\"int\").isNotNull() &\n",
        "                           (F.col(\"position\").cast(\"int\") >= 1)))\n",
        "\n",
        "        df = df.withColumn(\"is_valid_points\",\n",
        "                          (F.col(\"points\").isNotNull() &\n",
        "                           F.col(\"points\").cast(\"double\").isNotNull() &\n",
        "                           (F.col(\"points\").cast(\"double\") >= 0)))\n",
        "\n",
        "        df = df.withColumn(\"is_valid_grid\",\n",
        "                          (F.col(\"grid\").isNotNull() &\n",
        "                           F.col(\"grid\").cast(\"int\").isNotNull() &\n",
        "                           (F.col(\"grid\").cast(\"int\") >= 0)))\n",
        "\n",
        "        df = df.withColumn(\"is_valid_date\",\n",
        "                          F.col(\"race_timestamp\").isNotNull())\n",
        "\n",
        "        # Combine all checks\n",
        "        df = df.withColumn(\"is_valid_record\",\n",
        "                          F.col(\"is_valid_position\") &\n",
        "                          F.col(\"is_valid_points\") &\n",
        "                          F.col(\"is_valid_grid\") &\n",
        "                          F.col(\"is_valid_date\"))\n",
        "\n",
        "        # 6. Add metadata\n",
        "        df = df.withColumn(\"processed_timestamp\", F.current_timestamp())\n",
        "\n",
        "        # 7. Calculate quality metrics\n",
        "        total_records = df.count()\n",
        "        valid_records = df.filter(F.col(\"is_valid_record\")).count()\n",
        "        null_percentages = {}\n",
        "\n",
        "        for column in df.columns:\n",
        "            null_count = df.filter(F.col(column).isNull()).count()\n",
        "            null_percentages[column] = (null_count / total_records) * 100\n",
        "\n",
        "        print(\"\\nData Quality Metrics:\")\n",
        "        print(f\"Total Records: {total_records}\")\n",
        "        print(f\"Valid Records: {valid_records}\")\n",
        "        print(f\"Invalid Records: {total_records - valid_records}\")\n",
        "        print(\"\\nNull Percentages:\")\n",
        "        for col, pct in null_percentages.items():\n",
        "            if pct > 0:\n",
        "                print(f\"{col}: {pct:.2f}%\")\n",
        "\n",
        "        # 8. Write to silver layer\n",
        "        print(\"\\nWriting to silver layer...\")\n",
        "\n",
        "        # Write main dataset\n",
        "        silver_path = \"/content/drive/MyDrive/Capstone/silver\"\n",
        "        df.write.mode(\"overwrite\") \\\n",
        "            .partitionBy(\"season\") \\\n",
        "            .parquet(silver_path)\n",
        "\n",
        "        print(f\"\\nSilver layer data written to: {silver_path}\")\n",
        "        print(\"Silver Layer Processing Complete!\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Silver Layer Processing: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Execute the processing\n",
        "silver_df = process_f1_silver_layer()\n",
        "\n",
        "# Show sample of the processed data\n",
        "print(\"\\nSample of processed data:\")\n",
        "silver_df.show(5)"
      ]
    }
  ]
}